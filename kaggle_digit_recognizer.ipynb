{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "images, labels = [], []\n",
    "\n",
    "with open('train.csv') as train_file:\n",
    "    # Skip first line.\n",
    "    train_file.readline()\n",
    "    \n",
    "    csv_train_file = csv.reader(train_file, delimiter=',')\n",
    "    for row in csv_train_file:\n",
    "        labels.append(row[0])\n",
    "        images.append(np.array(row[1:], dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "#           Part One: Preprocess Data 1) Explore\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing sample with label 8.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f70b978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_index = 20\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sample, label = images[sample_index], labels[sample_index]\n",
    "plt.imshow(np.reshape(sample, (28, 28)), norm=matplotlib.colors.NoNorm())\n",
    "\n",
    "print(\"Printing sample with label %s.\" % (label))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing sample with normalzied pixels.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf13UmIMaRAm7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f9c9208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalizing a sample to scale of (0, 1)\n",
    "\n",
    "PIXEL_SCALE = 255\n",
    "normalized_sample = sample / PIXEL_SCALE\n",
    "plt.imshow(np.reshape(normalized_sample, (28, 28)), norm=matplotlib.colors.NoNorm())\n",
    "print(\"Printing sample with normalzied pixels.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "normalized_images = [image / PIXEL_SCALE for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################\n",
    "#           Part One: Preprocess Data 2) Split Data Set\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# One hot encoding labels.\n",
    "def one_hot_label(label):\n",
    "    one_hot_coded = np.zeros(10)\n",
    "    one_hot_coded[int(label)] = 1\n",
    "    return np.array(one_hot_coded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "combined = list(zip(images, labels))\n",
    "random.shuffle(combined)\n",
    "images[:], labels[:] = zip(*combined)\n",
    "\n",
    "validation_size = int(len(images) / 10)\n",
    "\n",
    "validate_images = [np.array(image).reshape((28, 28, 1)) for image in images[:validation_size]]\n",
    "validate_labels = [one_hot_label(label) for label in labels[:validation_size]]\n",
    "\n",
    "images = images[validation_size:]\n",
    "labels = labels[validation_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "################################################################\n",
    "#                Part Two: (1) Create Tensor\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conv_net_input(input_shape):\n",
    "    tensor_shape = [None] + list(input_shape)\n",
    "    return tf.placeholder(tf.float32, shape=tensor_shape, name='conv_input')\n",
    "\n",
    "def conv_net_label(label_shape):\n",
    "    label_shape = [None, label_shape]\n",
    "    return tf.placeholder(tf.float32, shape=label_shape, name='conv_label')\n",
    "\n",
    "def conv_net_dropout_prob():\n",
    "    return tf.placeholder(tf.float32, name='dropout_prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "#                Part Two: (2) Create Layer\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conv2d(input_tensor, kernel_depth=1, output_dim=32, k_size=3, padding='valid'):\n",
    "    \"\"\"\n",
    "    :param input_tensor: input tensor, should be reshaped to 2D\n",
    "    :param output_dim: output dimension, e.g. 32, 64, etc. \n",
    "    :param kernel_size: kernel size, 3, 5, etc.\n",
    "    \"\"\"\n",
    "    conv_layer = tf.layers.conv2d(input_tensor,\n",
    "                                  output_dim,\n",
    "                                  k_size,\n",
    "                                  padding=padding,\n",
    "                                  activation=tf.nn.relu)\n",
    "    \n",
    "    return conv_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def max_pool(input_tensor, pool_ksize, pool_strides, padding='valid'):\n",
    "    return tf.layers.max_pooling2d(\n",
    "        input_tensor,\n",
    "        pool_ksize,\n",
    "        pool_strides,\n",
    "        padding\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def flatten(input_tensor):\n",
    "    image_dimension = reduce(lambda a,b: a*b, input_tensor.get_shape().as_list()[1:])    \n",
    "    return tf.reshape(input_tensor, [-1, image_dimension])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def fully_connected_with_dropout(input_tensor, output_dim, dropout):    \n",
    "    fully_connected = tf.layers.dense(\n",
    "        input_tensor,\n",
    "        output_dim,\n",
    "    )\n",
    "    \n",
    "    dropout_layer = tf.layers.dropout(inputs=fully_connected, rate=dropout)    \n",
    "    \n",
    "    return dropout_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def output_layer(input_tensor, output_dim):    \n",
    "    return tf.layers.dense(\n",
    "        input_tensor,\n",
    "        output_dim,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class BatchLoader:\n",
    "    \n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.offset = 0\n",
    "        \n",
    "    def load_batch(self, batch_size):        \n",
    "        i = self.offset\n",
    "        image_batch = self.images[i: i + batch_size]\n",
    "        image_batch = [image.reshape((28, 28, 1)) for image in image_batch]\n",
    "                \n",
    "        label_batch = self.labels[i: i + batch_size]\n",
    "        label_batch = [one_hot_label(label) for label in label_batch]\n",
    "        self.offset += batch_size\n",
    "                \n",
    "        return image_batch, label_batch\n",
    "        \n",
    "    def reset(self):\n",
    "        self.offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "#                Part Two: (3) Create Model\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conv_net(image, dropout_prob):\n",
    "    \"\"\"\n",
    "    :param image: input image tensor.\n",
    "    :dropout_prob: drop out probability.\n",
    "    \"\"\"\n",
    "    # convolution - max pooling layer 1\n",
    "    conv_layer = conv2d(image, kernel_depth=1, output_dim=16, k_size=3)\n",
    "    mp_layer = max_pool(conv_layer, 2, 2)\n",
    "    \n",
    "    # convolution - max pooling layer 2\n",
    "    conv_layer = conv2d(mp_layer, kernel_depth=16, output_dim=32, k_size=3)\n",
    "    mp_layer = max_pool(conv_layer, 2, 2)\n",
    "    \n",
    "    # convolution - max pooling layer 3\n",
    "    conv_layer = conv2d(mp_layer, kernel_depth=32, output_dim=64, k_size=3)\n",
    "    mp_layer = max_pool(conv_layer, 2, 2)\n",
    "    \n",
    "    flat = flatten(mp_layer)\n",
    "    \n",
    "    # def fully_connected_with_dropout(input_tensor, output_dim, dropout):\n",
    "    \n",
    "    fully_conn = fully_connected_with_dropout(flat, 96, dropout_prob) \n",
    "    logits = output_layer(fully_conn, 10)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "#                Part Three: Define Loss & Accuracy\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "image_tensor = conv_net_input((28, 28, 1))\n",
    "label_tensor = conv_net_label(10)\n",
    "dropout_prob_tensor = conv_net_dropout_prob()\n",
    "\n",
    "# Module\n",
    "\n",
    "logits = conv_net(image_tensor, dropout_prob_tensor)\n",
    "\n",
    "# Loss & Optimizer\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=label_tensor))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(logits, axis=1), tf.argmax(label_tensor, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import reduce\n",
    "reduce((lambda a,b: a*b), [1,2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, image_batch, label_batch, t_type='Training'):\n",
    "#     print('label_batch: ', label_batch)\n",
    "    \n",
    "    _loss = session.run(loss, feed_dict={\n",
    "        image_tensor : image_batch,\n",
    "        label_tensor : label_batch,\n",
    "        dropout_prob_tensor : 0.0\n",
    "    })\n",
    "\n",
    "    _accuracy = session.run(accuracy, feed_dict={\n",
    "        image_tensor : image_batch,\n",
    "        label_tensor : label_batch,\n",
    "        dropout_prob_tensor : 0.0     \n",
    "    })\n",
    "    \n",
    "    _logits = session.run(logits, feed_dict={\n",
    "        image_tensor : image_batch,\n",
    "        label_tensor : label_batch,\n",
    "        dropout_prob_tensor : 0.0     \n",
    "    })\n",
    "    \n",
    "    _match = session.run(correct_pred, feed_dict={\n",
    "        image_tensor : image_batch,\n",
    "        label_tensor : label_batch,\n",
    "        dropout_prob_tensor : 0.0     \n",
    "    })\n",
    "    \n",
    "    print(t_type + ' loss: ', _loss)\n",
    "    print(t_type + ' accuracy: ', _accuracy)\n",
    "#     print('true labels: ', np.argmax(label_batch, axis=1))\n",
    "#     print('predicted labels ', np.argmax(_logits, axis=1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "#                Part Four: Training\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train_model(session, optimizer, image_batch, label_batch, dropout_prob):\n",
    "    \n",
    "#     print('image_batch shape: ', len(image_batch))\n",
    "#     print('label_batch shape: ', len(label_batch))\n",
    "#     print('dropout_prob shape: ', dropout_prob)\n",
    "    \n",
    "    session.run(\n",
    "        optimizer,\n",
    "        feed_dict={\n",
    "            image_tensor : image_batch,\n",
    "            label_tensor : label_batch,\n",
    "            dropout_prob_tensor : dropout_prob\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def run_model(epochs, images, labels, batch_size, dropout_prob):\n",
    "    \n",
    "    with tf.Session() as session:\n",
    "        \n",
    "        # Initializing the variables\n",
    "        session.run(tf.global_variables_initializer())\n",
    "    \n",
    "        # Prepare batches for images & labels\n",
    "        loader = BatchLoader(images, labels)\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            loader.reset()\n",
    "            \n",
    "            count = 0\n",
    "            \n",
    "            while True:                \n",
    "                image_batch, label_batch = loader.load_batch(batch_size)\n",
    "                count += 1\n",
    "                \n",
    "                # Process each batch.\n",
    "                if len(image_batch) != 0  and len(label_batch) != 0:                     \n",
    "                    train_model(session, optimizer, image_batch, label_batch, dropout_prob)\n",
    "                    \n",
    "                    # Print stats every 20 epochs.\n",
    "                    if count % 20 == 0:\n",
    "                        print('===============epoch: ', epoch, '=================')\n",
    "                        print_stats(session, image_batch, label_batch) \n",
    "                        print_stats(session, validate_images, validate_labels, t_type='Validate') \n",
    "                else:\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============epoch:  0 =================\n",
      "Training loss:  2.25588\n",
      "Training accuracy:  0.505\n",
      "Validate loss:  2.34835\n",
      "Validate accuracy:  0.472958\n",
      "===============epoch:  0 =================\n",
      "Training loss:  1.00664\n",
      "Training accuracy:  0.693333\n",
      "Validate loss:  1.02597\n",
      "Validate accuracy:  0.698004\n",
      "===============epoch:  1 =================\n",
      "Training loss:  0.618909\n",
      "Training accuracy:  0.821667\n",
      "Validate loss:  0.683807\n",
      "Validate accuracy:  0.801815\n",
      "===============epoch:  1 =================\n",
      "Training loss:  0.536786\n",
      "Training accuracy:  0.838333\n",
      "Validate loss:  0.544986\n",
      "Validate accuracy:  0.836661\n",
      "===============epoch:  2 =================\n",
      "Training loss:  0.387137\n",
      "Training accuracy:  0.893333\n",
      "Validate loss:  0.454568\n",
      "Validate accuracy:  0.867514\n",
      "===============epoch:  2 =================\n",
      "Training loss:  0.369853\n",
      "Training accuracy:  0.88\n",
      "Validate loss:  0.394009\n",
      "Validate accuracy:  0.888203\n",
      "===============epoch:  3 =================\n",
      "Training loss:  0.280276\n",
      "Training accuracy:  0.906667\n",
      "Validate loss:  0.346852\n",
      "Validate accuracy:  0.900544\n",
      "===============epoch:  3 =================\n",
      "Training loss:  0.267862\n",
      "Training accuracy:  0.906667\n",
      "Validate loss:  0.314609\n",
      "Validate accuracy:  0.910708\n",
      "===============epoch:  4 =================\n",
      "Training loss:  0.217417\n",
      "Training accuracy:  0.935\n",
      "Validate loss:  0.288301\n",
      "Validate accuracy:  0.919056\n",
      "===============epoch:  4 =================\n",
      "Training loss:  0.206821\n",
      "Training accuracy:  0.933333\n",
      "Validate loss:  0.265181\n",
      "Validate accuracy:  0.924138\n",
      "===============epoch:  5 =================\n",
      "Training loss:  0.177883\n",
      "Training accuracy:  0.953333\n",
      "Validate loss:  0.249836\n",
      "Validate accuracy:  0.929583\n",
      "===============epoch:  5 =================\n",
      "Training loss:  0.167556\n",
      "Training accuracy:  0.94\n",
      "Validate loss:  0.235505\n",
      "Validate accuracy:  0.933212\n",
      "===============epoch:  6 =================\n",
      "Training loss:  0.151601\n",
      "Training accuracy:  0.956667\n",
      "Validate loss:  0.223867\n",
      "Validate accuracy:  0.936842\n",
      "===============epoch:  6 =================\n",
      "Training loss:  0.139769\n",
      "Training accuracy:  0.946667\n",
      "Validate loss:  0.213924\n",
      "Validate accuracy:  0.939746\n",
      "===============epoch:  7 =================\n",
      "Training loss:  0.127319\n",
      "Training accuracy:  0.965\n",
      "Validate loss:  0.206646\n",
      "Validate accuracy:  0.941561\n",
      "===============epoch:  7 =================\n",
      "Training loss:  0.117232\n",
      "Training accuracy:  0.96\n",
      "Validate loss:  0.197798\n",
      "Validate accuracy:  0.943739\n",
      "===============epoch:  8 =================\n",
      "Training loss:  0.114045\n",
      "Training accuracy:  0.965\n",
      "Validate loss:  0.192229\n",
      "Validate accuracy:  0.946642\n",
      "===============epoch:  8 =================\n",
      "Training loss:  0.0991452\n",
      "Training accuracy:  0.973333\n",
      "Validate loss:  0.18599\n",
      "Validate accuracy:  0.947368\n",
      "===============epoch:  9 =================\n",
      "Training loss:  0.0979899\n",
      "Training accuracy:  0.973333\n",
      "Validate loss:  0.180363\n",
      "Validate accuracy:  0.954265\n",
      "===============epoch:  9 =================\n",
      "Training loss:  0.0833918\n",
      "Training accuracy:  0.978333\n",
      "Validate loss:  0.176741\n",
      "Validate accuracy:  0.949183\n",
      "===============epoch:  10 =================\n",
      "Training loss:  0.0861594\n",
      "Training accuracy:  0.971667\n",
      "Validate loss:  0.17338\n",
      "Validate accuracy:  0.956443\n",
      "===============epoch:  10 =================\n",
      "Training loss:  0.0730309\n",
      "Training accuracy:  0.983333\n",
      "Validate loss:  0.170448\n",
      "Validate accuracy:  0.952087\n",
      "===============epoch:  11 =================\n",
      "Training loss:  0.076153\n",
      "Training accuracy:  0.973333\n",
      "Validate loss:  0.166094\n",
      "Validate accuracy:  0.956806\n",
      "===============epoch:  11 =================\n",
      "Training loss:  0.0639973\n",
      "Training accuracy:  0.985\n",
      "Validate loss:  0.167277\n",
      "Validate accuracy:  0.954265\n",
      "===============epoch:  12 =================\n",
      "Training loss:  0.0679829\n",
      "Training accuracy:  0.976667\n",
      "Validate loss:  0.159839\n",
      "Validate accuracy:  0.957895\n",
      "===============epoch:  12 =================\n",
      "Training loss:  0.0548032\n",
      "Training accuracy:  0.983333\n",
      "Validate loss:  0.162739\n",
      "Validate accuracy:  0.956443\n",
      "===============epoch:  13 =================\n",
      "Training loss:  0.0617962\n",
      "Training accuracy:  0.983333\n",
      "Validate loss:  0.153756\n",
      "Validate accuracy:  0.958258\n",
      "===============epoch:  13 =================\n",
      "Training loss:  0.0469769\n",
      "Training accuracy:  0.985\n",
      "Validate loss:  0.161115\n",
      "Validate accuracy:  0.956443\n",
      "===============epoch:  14 =================\n",
      "Training loss:  0.0551946\n",
      "Training accuracy:  0.983333\n",
      "Validate loss:  0.15036\n",
      "Validate accuracy:  0.958621\n",
      "===============epoch:  14 =================\n",
      "Training loss:  0.0389915\n",
      "Training accuracy:  0.986667\n",
      "Validate loss:  0.161387\n",
      "Validate accuracy:  0.956443\n",
      "===============epoch:  15 =================\n",
      "Training loss:  0.0506688\n",
      "Training accuracy:  0.99\n",
      "Validate loss:  0.148005\n",
      "Validate accuracy:  0.961524\n",
      "===============epoch:  15 =================\n",
      "Training loss:  0.0353715\n",
      "Training accuracy:  0.988333\n",
      "Validate loss:  0.16063\n",
      "Validate accuracy:  0.95608\n",
      "===============epoch:  16 =================\n",
      "Training loss:  0.0485027\n",
      "Training accuracy:  0.988333\n",
      "Validate loss:  0.146461\n",
      "Validate accuracy:  0.962976\n",
      "===============epoch:  16 =================\n",
      "Training loss:  0.0316958\n",
      "Training accuracy:  0.99\n",
      "Validate loss:  0.160815\n",
      "Validate accuracy:  0.956443\n",
      "===============epoch:  17 =================\n",
      "Training loss:  0.0438726\n",
      "Training accuracy:  0.99\n",
      "Validate loss:  0.14549\n",
      "Validate accuracy:  0.963702\n",
      "===============epoch:  17 =================\n",
      "Training loss:  0.0274577\n",
      "Training accuracy:  0.993333\n",
      "Validate loss:  0.158774\n",
      "Validate accuracy:  0.957895\n",
      "===============epoch:  18 =================\n",
      "Training loss:  0.0411402\n",
      "Training accuracy:  0.99\n",
      "Validate loss:  0.147255\n",
      "Validate accuracy:  0.961524\n",
      "===============epoch:  18 =================\n",
      "Training loss:  0.0251998\n",
      "Training accuracy:  0.993333\n",
      "Validate loss:  0.158215\n",
      "Validate accuracy:  0.958984\n",
      "===============epoch:  19 =================\n",
      "Training loss:  0.0370459\n",
      "Training accuracy:  0.991667\n",
      "Validate loss:  0.146103\n",
      "Validate accuracy:  0.963702\n",
      "===============epoch:  19 =================\n",
      "Training loss:  0.0219997\n",
      "Training accuracy:  0.993333\n",
      "Validate loss:  0.155347\n",
      "Validate accuracy:  0.961887\n",
      "===============epoch:  20 =================\n",
      "Training loss:  0.0334628\n",
      "Training accuracy:  0.993333\n",
      "Validate loss:  0.145649\n",
      "Validate accuracy:  0.963339\n",
      "===============epoch:  20 =================\n",
      "Training loss:  0.0195645\n",
      "Training accuracy:  0.996667\n",
      "Validate loss:  0.149685\n",
      "Validate accuracy:  0.964791\n",
      "===============epoch:  21 =================\n",
      "Training loss:  0.0271085\n",
      "Training accuracy:  0.996667\n",
      "Validate loss:  0.140138\n",
      "Validate accuracy:  0.964428\n",
      "===============epoch:  21 =================\n",
      "Training loss:  0.0176391\n",
      "Training accuracy:  0.995\n",
      "Validate loss:  0.144835\n",
      "Validate accuracy:  0.964065\n",
      "===============epoch:  22 =================\n",
      "Training loss:  0.0246101\n",
      "Training accuracy:  0.996667\n",
      "Validate loss:  0.146948\n",
      "Validate accuracy:  0.964428\n",
      "===============epoch:  22 =================\n",
      "Training loss:  0.0160381\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.140662\n",
      "Validate accuracy:  0.965154\n",
      "===============epoch:  23 =================\n",
      "Training loss:  0.0224867\n",
      "Training accuracy:  0.996667\n",
      "Validate loss:  0.144033\n",
      "Validate accuracy:  0.966243\n",
      "===============epoch:  23 =================\n",
      "Training loss:  0.0156792\n",
      "Training accuracy:  0.996667\n",
      "Validate loss:  0.141898\n",
      "Validate accuracy:  0.966969\n",
      "===============epoch:  24 =================\n",
      "Training loss:  0.0189168\n",
      "Training accuracy:  0.996667\n",
      "Validate loss:  0.142399\n",
      "Validate accuracy:  0.967332\n",
      "===============epoch:  24 =================\n",
      "Training loss:  0.0160707\n",
      "Training accuracy:  0.995\n",
      "Validate loss:  0.147986\n",
      "Validate accuracy:  0.968784\n",
      "===============epoch:  25 =================\n",
      "Training loss:  0.016152\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.143354\n",
      "Validate accuracy:  0.968058\n",
      "===============epoch:  25 =================\n",
      "Training loss:  0.0152408\n",
      "Training accuracy:  0.996667\n",
      "Validate loss:  0.14892\n",
      "Validate accuracy:  0.966606\n",
      "===============epoch:  26 =================\n",
      "Training loss:  0.0134498\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.146754\n",
      "Validate accuracy:  0.968058\n",
      "===============epoch:  26 =================\n",
      "Training loss:  0.014645\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.149128\n",
      "Validate accuracy:  0.967332\n",
      "===============epoch:  27 =================\n",
      "Training loss:  0.0124047\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.148986\n",
      "Validate accuracy:  0.968058\n",
      "===============epoch:  27 =================\n",
      "Training loss:  0.0122919\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.155182\n",
      "Validate accuracy:  0.964065\n",
      "===============epoch:  28 =================\n",
      "Training loss:  0.0136914\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.148217\n",
      "Validate accuracy:  0.96951\n",
      "===============epoch:  28 =================\n",
      "Training loss:  0.0117499\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.160535\n",
      "Validate accuracy:  0.963702\n",
      "===============epoch:  29 =================\n",
      "Training loss:  0.0133268\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.147962\n",
      "Validate accuracy:  0.970962\n",
      "===============epoch:  29 =================\n",
      "Training loss:  0.0117102\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.165523\n",
      "Validate accuracy:  0.962976\n",
      "===============epoch:  30 =================\n",
      "Training loss:  0.0102086\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.153297\n",
      "Validate accuracy:  0.966969\n",
      "===============epoch:  30 =================\n",
      "Training loss:  0.0101861\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.169325\n",
      "Validate accuracy:  0.962976\n",
      "===============epoch:  31 =================\n",
      "Training loss:  0.0123987\n",
      "Training accuracy:  0.996667\n",
      "Validate loss:  0.151705\n",
      "Validate accuracy:  0.967332\n",
      "===============epoch:  31 =================\n",
      "Training loss:  0.0138471\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.181674\n",
      "Validate accuracy:  0.96225\n",
      "===============epoch:  32 =================\n",
      "Training loss:  0.013514\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.159775\n",
      "Validate accuracy:  0.962976\n",
      "===============epoch:  32 =================\n",
      "Training loss:  0.012814\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.173882\n",
      "Validate accuracy:  0.96225\n",
      "===============epoch:  33 =================\n",
      "Training loss:  0.0124043\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.145747\n",
      "Validate accuracy:  0.971325\n",
      "===============epoch:  33 =================\n",
      "Training loss:  0.00808901\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.148502\n",
      "Validate accuracy:  0.968058\n",
      "===============epoch:  34 =================\n",
      "Training loss:  0.00992136\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.154805\n",
      "Validate accuracy:  0.969873\n",
      "===============epoch:  34 =================\n",
      "Training loss:  0.0100029\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.153475\n",
      "Validate accuracy:  0.965154\n",
      "===============epoch:  35 =================\n",
      "Training loss:  0.00814253\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.159205\n",
      "Validate accuracy:  0.96951\n",
      "===============epoch:  35 =================\n",
      "Training loss:  0.00356817\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.151617\n",
      "Validate accuracy:  0.970236\n",
      "===============epoch:  36 =================\n",
      "Training loss:  0.00483789\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.158584\n",
      "Validate accuracy:  0.970599\n",
      "===============epoch:  36 =================\n",
      "Training loss:  0.00532988\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.167328\n",
      "Validate accuracy:  0.966243\n",
      "===============epoch:  37 =================\n",
      "Training loss:  0.00735256\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.164285\n",
      "Validate accuracy:  0.967695\n",
      "===============epoch:  37 =================\n",
      "Training loss:  0.00593733\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.17382\n",
      "Validate accuracy:  0.965154\n",
      "===============epoch:  38 =================\n",
      "Training loss:  0.00914972\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.174374\n",
      "Validate accuracy:  0.966606\n",
      "===============epoch:  38 =================\n",
      "Training loss:  0.00493518\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.171247\n",
      "Validate accuracy:  0.966969\n",
      "===============epoch:  39 =================\n",
      "Training loss:  0.00906469\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.181704\n",
      "Validate accuracy:  0.96588\n",
      "===============epoch:  39 =================\n",
      "Training loss:  0.00485307\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.179638\n",
      "Validate accuracy:  0.96588\n",
      "===============epoch:  40 =================\n",
      "Training loss:  0.00746298\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.189449\n",
      "Validate accuracy:  0.966969\n",
      "===============epoch:  40 =================\n",
      "Training loss:  0.0061871\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.193538\n",
      "Validate accuracy:  0.964428\n",
      "===============epoch:  41 =================\n",
      "Training loss:  0.00780201\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.201246\n",
      "Validate accuracy:  0.965154\n",
      "===============epoch:  41 =================\n",
      "Training loss:  0.00335375\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.188695\n",
      "Validate accuracy:  0.965154\n",
      "===============epoch:  42 =================\n",
      "Training loss:  0.00784533\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.219289\n",
      "Validate accuracy:  0.962613\n",
      "===============epoch:  42 =================\n",
      "Training loss:  0.0054021\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.180828\n",
      "Validate accuracy:  0.967695\n",
      "===============epoch:  43 =================\n",
      "Training loss:  0.00708091\n",
      "Training accuracy:  0.996667\n",
      "Validate loss:  0.207088\n",
      "Validate accuracy:  0.965154\n",
      "===============epoch:  43 =================\n",
      "Training loss:  0.00866963\n",
      "Training accuracy:  0.996667\n",
      "Validate loss:  0.191462\n",
      "Validate accuracy:  0.96588\n",
      "===============epoch:  44 =================\n",
      "Training loss:  0.00420118\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.180085\n",
      "Validate accuracy:  0.967695\n",
      "===============epoch:  44 =================\n",
      "Training loss:  0.00951476\n",
      "Training accuracy:  0.995\n",
      "Validate loss:  0.199319\n",
      "Validate accuracy:  0.963339\n",
      "===============epoch:  45 =================\n",
      "Training loss:  0.00747845\n",
      "Training accuracy:  0.996667\n",
      "Validate loss:  0.199781\n",
      "Validate accuracy:  0.964428\n",
      "===============epoch:  45 =================\n",
      "Training loss:  0.00464922\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.183013\n",
      "Validate accuracy:  0.965154\n",
      "===============epoch:  46 =================\n",
      "Training loss:  0.0100017\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.201212\n",
      "Validate accuracy:  0.962613\n",
      "===============epoch:  46 =================\n",
      "Training loss:  0.00520309\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.168799\n",
      "Validate accuracy:  0.966606\n",
      "===============epoch:  47 =================\n",
      "Training loss:  0.00669253\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.18497\n",
      "Validate accuracy:  0.966606\n",
      "===============epoch:  47 =================\n",
      "Training loss:  0.00649008\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.19555\n",
      "Validate accuracy:  0.964428\n",
      "===============epoch:  48 =================\n",
      "Training loss:  0.00329422\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.188921\n",
      "Validate accuracy:  0.966606\n",
      "===============epoch:  48 =================\n",
      "Training loss:  0.00772224\n",
      "Training accuracy:  0.996667\n",
      "Validate loss:  0.222275\n",
      "Validate accuracy:  0.961524\n",
      "===============epoch:  49 =================\n",
      "Training loss:  0.00488507\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.19823\n",
      "Validate accuracy:  0.964428\n",
      "===============epoch:  49 =================\n",
      "Training loss:  0.00520694\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.208573\n",
      "Validate accuracy:  0.962976\n",
      "===============epoch:  50 =================\n",
      "Training loss:  0.0044694\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.188962\n",
      "Validate accuracy:  0.968421\n",
      "===============epoch:  50 =================\n",
      "Training loss:  0.00294869\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.194273\n",
      "Validate accuracy:  0.966969\n",
      "===============epoch:  51 =================\n",
      "Training loss:  0.00290264\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.181961\n",
      "Validate accuracy:  0.969147\n",
      "===============epoch:  51 =================\n",
      "Training loss:  0.00454511\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.212695\n",
      "Validate accuracy:  0.965517\n",
      "===============epoch:  52 =================\n",
      "Training loss:  0.00149452\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.185096\n",
      "Validate accuracy:  0.966606\n",
      "===============epoch:  52 =================\n",
      "Training loss:  0.00530059\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.214112\n",
      "Validate accuracy:  0.964428\n",
      "===============epoch:  53 =================\n",
      "Training loss:  0.00321912\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.188169\n",
      "Validate accuracy:  0.968421\n",
      "===============epoch:  53 =================\n",
      "Training loss:  0.00294633\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.198916\n",
      "Validate accuracy:  0.96588\n",
      "===============epoch:  54 =================\n",
      "Training loss:  0.0021166\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.191173\n",
      "Validate accuracy:  0.966606\n",
      "===============epoch:  54 =================\n",
      "Training loss:  0.00190998\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.196155\n",
      "Validate accuracy:  0.966969\n",
      "===============epoch:  55 =================\n",
      "Training loss:  0.00387461\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.189325\n",
      "Validate accuracy:  0.96588\n",
      "===============epoch:  55 =================\n",
      "Training loss:  0.00297674\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.193997\n",
      "Validate accuracy:  0.967332\n",
      "===============epoch:  56 =================\n",
      "Training loss:  0.00303568\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.196025\n",
      "Validate accuracy:  0.968058\n",
      "===============epoch:  56 =================\n",
      "Training loss:  0.00390903\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.196141\n",
      "Validate accuracy:  0.966243\n",
      "===============epoch:  57 =================\n",
      "Training loss:  0.00497545\n",
      "Training accuracy:  0.996667\n",
      "Validate loss:  0.19722\n",
      "Validate accuracy:  0.970236\n",
      "===============epoch:  57 =================\n",
      "Training loss:  0.00319506\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.208729\n",
      "Validate accuracy:  0.966606\n",
      "===============epoch:  58 =================\n",
      "Training loss:  0.00359357\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.209328\n",
      "Validate accuracy:  0.967332\n",
      "===============epoch:  58 =================\n",
      "Training loss:  0.00241278\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.20753\n",
      "Validate accuracy:  0.965154\n",
      "===============epoch:  59 =================\n",
      "Training loss:  0.00132184\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.190231\n",
      "Validate accuracy:  0.969147\n",
      "===============epoch:  59 =================\n",
      "Training loss:  0.00698603\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.213493\n",
      "Validate accuracy:  0.962613\n",
      "===============epoch:  60 =================\n",
      "Training loss:  0.00138192\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.199236\n",
      "Validate accuracy:  0.96951\n",
      "===============epoch:  60 =================\n",
      "Training loss:  0.00239399\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.206804\n",
      "Validate accuracy:  0.964428\n",
      "===============epoch:  61 =================\n",
      "Training loss:  0.00275667\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.224226\n",
      "Validate accuracy:  0.963339\n",
      "===============epoch:  61 =================\n",
      "Training loss:  0.00233432\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.193154\n",
      "Validate accuracy:  0.969873\n",
      "===============epoch:  62 =================\n",
      "Training loss:  0.00137576\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.200891\n",
      "Validate accuracy:  0.968784\n",
      "===============epoch:  62 =================\n",
      "Training loss:  0.00269918\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.212034\n",
      "Validate accuracy:  0.967332\n",
      "===============epoch:  63 =================\n",
      "Training loss:  0.00195627\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.193845\n",
      "Validate accuracy:  0.967695\n",
      "===============epoch:  63 =================\n",
      "Training loss:  0.00216529\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.195134\n",
      "Validate accuracy:  0.967695\n",
      "===============epoch:  64 =================\n",
      "Training loss:  0.00276058\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.220124\n",
      "Validate accuracy:  0.965154\n",
      "===============epoch:  64 =================\n",
      "Training loss:  0.000842955\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.193972\n",
      "Validate accuracy:  0.968058\n",
      "===============epoch:  65 =================\n",
      "Training loss:  0.00221533\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.213781\n",
      "Validate accuracy:  0.966606\n",
      "===============epoch:  65 =================\n",
      "Training loss:  0.000846205\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.198311\n",
      "Validate accuracy:  0.968784\n",
      "===============epoch:  66 =================\n",
      "Training loss:  0.00163578\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.199595\n",
      "Validate accuracy:  0.967332\n",
      "===============epoch:  66 =================\n",
      "Training loss:  0.00111221\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.199917\n",
      "Validate accuracy:  0.970236\n",
      "===============epoch:  67 =================\n",
      "Training loss:  0.000424899\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.197976\n",
      "Validate accuracy:  0.966969\n",
      "===============epoch:  67 =================\n",
      "Training loss:  0.00156577\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.197776\n",
      "Validate accuracy:  0.96951\n",
      "===============epoch:  68 =================\n",
      "Training loss:  0.0010434\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.189165\n",
      "Validate accuracy:  0.971325\n",
      "===============epoch:  68 =================\n",
      "Training loss:  0.000225412\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.191392\n",
      "Validate accuracy:  0.970962\n",
      "===============epoch:  69 =================\n",
      "Training loss:  0.000664904\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.197679\n",
      "Validate accuracy:  0.969147\n",
      "===============epoch:  69 =================\n",
      "Training loss:  0.000460373\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.200434\n",
      "Validate accuracy:  0.971325\n",
      "===============epoch:  70 =================\n",
      "Training loss:  0.000573793\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.193469\n",
      "Validate accuracy:  0.969873\n",
      "===============epoch:  70 =================\n",
      "Training loss:  0.00258854\n",
      "Training accuracy:  0.998333\n",
      "Validate loss:  0.195399\n",
      "Validate accuracy:  0.970962\n",
      "===============epoch:  71 =================\n",
      "Training loss:  0.000895033\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.195815\n",
      "Validate accuracy:  0.970599\n",
      "===============epoch:  71 =================\n",
      "Training loss:  0.00104126\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.218249\n",
      "Validate accuracy:  0.970599\n",
      "===============epoch:  72 =================\n",
      "Training loss:  0.000383033\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.19879\n",
      "Validate accuracy:  0.972051\n",
      "===============epoch:  72 =================\n",
      "Training loss:  0.000157504\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.204459\n",
      "Validate accuracy:  0.970599\n",
      "===============epoch:  73 =================\n",
      "Training loss:  0.000535212\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.194285\n",
      "Validate accuracy:  0.971688\n",
      "===============epoch:  73 =================\n",
      "Training loss:  0.000248735\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.199799\n",
      "Validate accuracy:  0.971688\n",
      "===============epoch:  74 =================\n",
      "Training loss:  0.000265149\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.198258\n",
      "Validate accuracy:  0.971688\n",
      "===============epoch:  74 =================\n",
      "Training loss:  0.000163909\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.197562\n",
      "Validate accuracy:  0.97314\n",
      "===============epoch:  75 =================\n",
      "Training loss:  0.000152651\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.197066\n",
      "Validate accuracy:  0.972051\n",
      "===============epoch:  75 =================\n",
      "Training loss:  0.000128764\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.196747\n",
      "Validate accuracy:  0.972414\n",
      "===============epoch:  76 =================\n",
      "Training loss:  9.45741e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.196873\n",
      "Validate accuracy:  0.972777\n",
      "===============epoch:  76 =================\n",
      "Training loss:  0.00011921\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.197161\n",
      "Validate accuracy:  0.972777\n",
      "===============epoch:  77 =================\n",
      "Training loss:  9.33475e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.197312\n",
      "Validate accuracy:  0.972051\n",
      "===============epoch:  77 =================\n",
      "Training loss:  0.000107916\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.197555\n",
      "Validate accuracy:  0.972777\n",
      "===============epoch:  78 =================\n",
      "Training loss:  9.00141e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.197724\n",
      "Validate accuracy:  0.972051\n",
      "===============epoch:  78 =================\n",
      "Training loss:  0.000100049\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.198\n",
      "Validate accuracy:  0.972414\n",
      "===============epoch:  79 =================\n",
      "Training loss:  8.73454e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.198161\n",
      "Validate accuracy:  0.971688\n",
      "===============epoch:  79 =================\n",
      "Training loss:  9.33851e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.198449\n",
      "Validate accuracy:  0.971688\n",
      "===============epoch:  80 =================\n",
      "Training loss:  8.48777e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.19862\n",
      "Validate accuracy:  0.971325\n",
      "===============epoch:  80 =================\n",
      "Training loss:  8.75886e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.198888\n",
      "Validate accuracy:  0.971688\n",
      "===============epoch:  81 =================\n",
      "Training loss:  8.24362e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.199062\n",
      "Validate accuracy:  0.971688\n",
      "===============epoch:  81 =================\n",
      "Training loss:  8.25965e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.199329\n",
      "Validate accuracy:  0.972051\n",
      "===============epoch:  82 =================\n",
      "Training loss:  8.026e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.199493\n",
      "Validate accuracy:  0.971688\n",
      "===============epoch:  82 =================\n",
      "Training loss:  7.8226e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.199744\n",
      "Validate accuracy:  0.972051\n",
      "===============epoch:  83 =================\n",
      "Training loss:  7.81513e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.199851\n",
      "Validate accuracy:  0.972051\n",
      "===============epoch:  83 =================\n",
      "Training loss:  7.43559e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.200112\n",
      "Validate accuracy:  0.972051\n",
      "===============epoch:  84 =================\n",
      "Training loss:  7.63678e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.200205\n",
      "Validate accuracy:  0.972051\n",
      "===============epoch:  84 =================\n",
      "Training loss:  7.0785e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.200455\n",
      "Validate accuracy:  0.972051\n",
      "===============epoch:  85 =================\n",
      "Training loss:  7.45372e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.200554\n",
      "Validate accuracy:  0.972051\n",
      "===============epoch:  85 =================\n",
      "Training loss:  6.77897e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.200809\n",
      "Validate accuracy:  0.972051\n",
      "===============epoch:  86 =================\n",
      "Training loss:  7.29371e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.200926\n",
      "Validate accuracy:  0.972051\n",
      "===============epoch:  86 =================\n",
      "Training loss:  6.50447e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.201164\n",
      "Validate accuracy:  0.972051\n",
      "===============epoch:  87 =================\n",
      "Training loss:  7.10953e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.201251\n",
      "Validate accuracy:  0.972051\n",
      "===============epoch:  87 =================\n",
      "Training loss:  6.2437e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.201459\n",
      "Validate accuracy:  0.972051\n",
      "===============epoch:  88 =================\n",
      "Training loss:  6.92982e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.201576\n",
      "Validate accuracy:  0.972051\n",
      "===============epoch:  88 =================\n",
      "Training loss:  6.00975e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.201777\n",
      "Validate accuracy:  0.972051\n",
      "===============epoch:  89 =================\n",
      "Training loss:  6.76336e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.201893\n",
      "Validate accuracy:  0.972051\n",
      "===============epoch:  89 =================\n",
      "Training loss:  5.79549e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.202078\n",
      "Validate accuracy:  0.972051\n",
      "===============epoch:  90 =================\n",
      "Training loss:  6.60522e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.202172\n",
      "Validate accuracy:  0.972051\n",
      "===============epoch:  90 =================\n",
      "Training loss:  5.58668e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.202402\n",
      "Validate accuracy:  0.972051\n",
      "===============epoch:  91 =================\n",
      "Training loss:  6.42785e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.202527\n",
      "Validate accuracy:  0.972051\n",
      "===============epoch:  91 =================\n",
      "Training loss:  5.40167e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.202723\n",
      "Validate accuracy:  0.972051\n",
      "===============epoch:  92 =================\n",
      "Training loss:  6.28458e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.202827\n",
      "Validate accuracy:  0.971688\n",
      "===============epoch:  92 =================\n",
      "Training loss:  5.22617e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.203023\n",
      "Validate accuracy:  0.972051\n",
      "===============epoch:  93 =================\n",
      "Training loss:  6.1317e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.203124\n",
      "Validate accuracy:  0.971688\n",
      "===============epoch:  93 =================\n",
      "Training loss:  5.06669e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.203315\n",
      "Validate accuracy:  0.972051\n",
      "===============epoch:  94 =================\n",
      "Training loss:  5.97698e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.203454\n",
      "Validate accuracy:  0.971688\n",
      "===============epoch:  94 =================\n",
      "Training loss:  4.91389e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.203628\n",
      "Validate accuracy:  0.972051\n",
      "===============epoch:  95 =================\n",
      "Training loss:  5.82172e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.203733\n",
      "Validate accuracy:  0.971688\n",
      "===============epoch:  95 =================\n",
      "Training loss:  4.76494e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.203864\n",
      "Validate accuracy:  0.971688\n",
      "===============epoch:  96 =================\n",
      "Training loss:  5.68592e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.203994\n",
      "Validate accuracy:  0.971325\n",
      "===============epoch:  96 =================\n",
      "Training loss:  4.63744e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.204134\n",
      "Validate accuracy:  0.971688\n",
      "===============epoch:  97 =================\n",
      "Training loss:  5.53423e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.204291\n",
      "Validate accuracy:  0.971325\n",
      "===============epoch:  97 =================\n",
      "Training loss:  4.50902e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.204449\n",
      "Validate accuracy:  0.971688\n",
      "===============epoch:  98 =================\n",
      "Training loss:  5.41351e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.204583\n",
      "Validate accuracy:  0.971325\n",
      "===============epoch:  98 =================\n",
      "Training loss:  4.37594e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.204714\n",
      "Validate accuracy:  0.971688\n",
      "===============epoch:  99 =================\n",
      "Training loss:  5.27442e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.204835\n",
      "Validate accuracy:  0.970962\n",
      "===============epoch:  99 =================\n",
      "Training loss:  4.25982e-05\n",
      "Training accuracy:  1.0\n",
      "Validate loss:  0.205003\n",
      "Validate accuracy:  0.971325\n"
     ]
    }
   ],
   "source": [
    "run_model(100, images, labels, 600, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(len(images))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
